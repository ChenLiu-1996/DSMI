import os
import sys
from typing import Dict, List, Literal, Tuple, Union

import torch
import yaml

sys.path.insert(0, os.path.abspath('../../external_src/insgen/'))
import dnnlib
import legacy

sys.path.insert(0, os.path.abspath('../../utils/'))
from attribute_hashmap import AttributeHashmap
from log_utils import log


class InsGenModel(object):
    '''
    Wrapper class for InsGen model.
        "Data-Efficient Instance Generation from Instance Discrimination." NeurIPS 2021.
        Paper: https://arxiv.org/abs/2106.04566
        Code: https://github.com/genforce/insgen
    '''

    def __init__(self,
                 device: torch.device = torch.device('cuda'),
                 domain: str = 'ffhq_256') -> None:
        '''
        Arg(s):
            device : torch.device
                Device to run model.
            domain : str
                Domain of the generated images -- usually the dataset on which the model is trained.
                This may impact the model architecture and/or other settings.
                Currently supported: ['ffhq_256']
        '''

        self.device = device
        self.domain = domain

        # A list of supported `domains`.
        self.__domains = ['ffhq_256']

        # A hashmap from `domain` to the path of the corresponding config yaml file.
        self.__domain2config = {}
        for d in self.__domains:
            self.__domain2config[d] = os.path.abspath(
                '../configs/insgen/insgen_config_%s.yaml' % d)

        # Sanity check.
        if self.domain not in self.__domains:
            raise ValueError(
                'In `InsGenModel.__init__`: value of input argument `domain` is invalid. ' + \
                'Value provided: `%s`. Values allowed: %s.' % (domain, self.__domains)
            )

        # Load and parse the config yaml file.
        config = parse_config(self.__domain2config[self.domain])
        self.pretrained_path = config.pretrained_path

        # Instantiate model.
        with dnnlib.util.open_url(self.pretrained_path) as f:
            self.model = legacy.load_network_pkl(f)['G_ema']
            # Re-initialize the weights (allowing for training from scratch).
            self.model.__init__(self.model.z_dim, self.model.c_dim,
                                self.model.w_dim, self.model.img_resolution,
                                self.model.img_channels)
            self.model.to(self.device)
        log('`InsGenModel`: model successfully instantiated.', to_console=True)

        # Register hook to allow accessing of latent outputs.
        self.track_latent()

        # Propagate the `z_dim` attribute.
        self.z_dim = self.model.z_dim

    def forward(
        self,
        noise,
        class_idx: int = None,
        truncation_psi: float = 1,
        noise_mode: Literal['const', 'random',
                            'none'] = 'const') -> torch.Tensor:
        '''
        Forwards noise through network

        Arg(s):
            noise : torch.Tensor[float32]
                N x M noise vector or image
        Returns:
            torch.Tensor[float32] : N x 3 x H x W
        '''

        noise = self.__transform_inputs(noise)

        label = torch.zeros([1, self.model.c_dim], device=self.device)
        if self.model.c_dim != 0:
            if class_idx is None:
                raise ValueError(
                    '`InsGenModel.forward(): Must specify class label with `class_idx` when using a conditional network.'
                )
            label[:, class_idx] = 1
        else:
            if class_idx is not None:
                log('[Warning] `InsGenModel.forward(): `class_idx` ignored when running on an unconditional network.',
                    to_console=True)

        img = self.model(noise,
                         label,
                         truncation_psi=truncation_psi,
                         noise_mode=noise_mode)
        img = (img * 127.5 + 128).clamp(0, 255).to(torch.uint8)

        return img

    def __transform_inputs(self, _in: torch.Tensor) -> torch.Tensor:
        '''
        Transforms the inputs based on specified by model

        Arg(s):
            _in : torch.Tensor[float32]
                N x M noise vector or image
        Returns:
            torch.Tensor[float32] : N x M vector or image
        '''

        return _in

    def compute_loss(
            self, output_image: torch.Tensor
    ) -> Tuple[float, Dict[str, torch.Tensor]]:
        '''
        Computes training loss

        Arg(s):
            output_image : torch.Tensor[float32]
                N x 3 x H x W image generated by network
        Returns:
            float : loss
            dict[str, torch.Tensor[float32]] : hashmap of loss related items
        '''

        loss = 0.0
        loss_info = {}

        # TODO: implement switch logic to compute loss for each NVAE model

        return loss, loss_info

    def __track_latent(self, name: str) -> torch.utils.hooks.RemovableHandle:
        '''
        Extracting Intermediate Layer Outputs.
        Code adapted from
        https://www.kaggle.com/code/mohammaddehghan/pytorch-extracting-intermediate-layer-outputs
        https://kozodoi.me/python/deep%20learning/pytorch/tutorial/2021/05/27/extracting-features.html
        '''

        if not hasattr(self, 'latent_outputs'):
            # A hashmap (key, value) to store the latent outputs.
            # key: layer name; value: layer output.
            self.latent_outputs = {}

        def hook(model, input, output):
            self.latent_outputs[name] = output.detach()

        return hook

    def track_latent(self) -> None:
        '''
        Register hook to allow accessing of latent outputs.
        '''
        for name, module in self.model.synthesis._modules.items():
            module.conv1.register_forward_hook(
                self.__track_latent('synthesis_%s_%s' % (name, 'conv1')))

    def fetch_latent(self) -> Dict[str, torch.Tensor]:
        '''
        Fetches latent from network

        Returns:
            dict[str, torch.Tensor[float32]] :
                hashmap of latent layer name and the corresponding output with shape [N, F, h, w]
        '''

        return self.latent_outputs

    def parameters(self) -> List[torch.Tensor]:
        '''
        Returns the list of parameters in the model

        Returns:
            List[torch.Tensor[float32]] : list of parameters
        '''

        return self.model.parameters()

    def named_parameters(self) -> Dict[str, torch.Tensor]:
        '''
        Returns the list of named parameters in the model

        Returns:
            dict[str, torch.Tensor[float32]] : list of parameters
        '''

        return self.model.named_parameters()

    def train(self) -> None:
        '''
        Sets model to training mode

        Arg(s):
            flag_only : bool
                if set, then only sets the train flag, but not mode
        '''

        return self.model.train()

    def eval(self) -> None:
        '''
        Sets model to evaluation mode
        '''

        return self.model.eval()

    def save_model(self, save_path: str) -> None:
        '''
        Stores weights into a checkpoint

        Arg(s):
            save_path : str
                path to model weights
        '''

        torch.save(self.model.state_dict(), save_path)

    def restore_model(self, restore_path: Union[str, None] = None) -> None:
        '''
        Loads weights from checkpoint

        Arg(s):
            restore_path : str
                path to model weights
        '''
        if restore_path is None:
            restore_path = self.pretrained_path

        with dnnlib.util.open_url(restore_path) as f:
            self.model = legacy.load_network_pkl(f)['G_ema']
            self.model.to(self.device)
        log('`InsGenModel`: model weights loaded from %s.' % restore_path,
            to_console=True)

        # Need to re-track latent after redefining model.
        self.track_latent()


def parse_config(config_file: str = None) -> AttributeHashmap:
    config = yaml.safe_load(open(os.path.abspath(config_file)))
    config = AttributeHashmap(config)
    return config
